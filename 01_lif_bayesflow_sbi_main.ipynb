{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation-Based Inference for a LIF Neuron (BayesFlow)\n",
    "\n",
    "This notebook is a *frozen snapshot* of the project used to generate the figures in `figures/`.\n",
    "\n",
    "**Workflow overview**\n",
    "1. Imports + plotting defaults\n",
    "2. LIF simulator and parameterization\n",
    "3. Prior definition and BayesFlow simulator wrapper\n",
    "4. Sanity checks (prior draws)\n",
    "5. BayesFlow workflow (adapter + networks)\n",
    "6. Offline training\n",
    "7. Diagnostics: loss, recovery, calibration (SBC)\n",
    "8. Single-example posterior + posterior predictive checks (PPC)\n",
    "\n",
    "> **Reproducibility note:** This notebook depends on BayesFlow + JAX/Keras backend versions.\n",
    "\n",
    "---\n"
   ],
   "id": "c8cb908c3db4b069"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "import bayesflow\n",
    "# @title Figure Settings\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True\n",
    "\n",
    "import ipywidgets as widgets  # interactive display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# use NMA plot style\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/nma.mplstyle\")\n",
    "my_layout = widgets.Layout()\n",
    "\n",
    "np.random.seed(45)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T19:03:26.351103Z",
     "start_time": "2025-08-10T19:03:19.146116Z"
    }
   },
   "id": "2a84930b7192ad9b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Imports and environment\n",
    "\n",
    "- Sets the Keras backend to **JAX** (required by the original setup).\n",
    "- Imports BayesFlow and plotting utilities.\n",
    "- Optional: applies a custom Matplotlib style.\n"
   ],
   "id": "77ad7607127e2325"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# @markdown Execute this code to initialize the default parameters\n",
    "from keras.src.utils.module_utils import jax\n",
    "# Set seeds for reproducibility\n",
    "jax_seed = jax.random.PRNGKey(45)\n",
    "\n",
    "# Default parameters\n",
    "def default_pars(**kwargs):\n",
    "    pars = {\n",
    "        'tref': 2.,  # Refractory time (ms)\n",
    "        'T': 200.,   # Simulation duration (ms)\n",
    "        'dt': 0.2,   # Time step (ms)\n",
    "    }\n",
    "    pars['range_t'] = np.arange(0, pars['T'], pars['dt'])\n",
    "    for k in kwargs:\n",
    "        pars[k] = kwargs[k]\n",
    "    return pars\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T19:05:06.225002Z",
     "start_time": "2025-08-10T19:05:06.111166Z"
    }
   },
   "id": "c50dc97157c82b0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Default simulation settings\n",
    "\n",
    "Defines the time grid and shared simulation hyperparameters (duration, time step, refractory period). Also sets the random seed for reproducibility.\n"
   ],
   "id": "f80084ad4d4f66e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# LIF model\n",
    "def run_LIF(pars, Iinj=None, noise_std=50):\n",
    "    # Validate parameters\n",
    "    if pars['tau_m'] <= 0 or pars['g_L'] <= 0:\n",
    "        raise ValueError(\"tau_m and g_L must be positive\")\n",
    "    if pars['V_th'] <= pars['V_reset']:\n",
    "        raise ValueError(\"V_th must be greater than V_reset\")\n",
    "    \n",
    "    V_th, V_reset = pars['V_th'], pars['V_reset']\n",
    "    tau_m, g_L = pars['tau_m'], pars['g_L']\n",
    "    V_init, E_L = pars['V_init'], pars['E_L']\n",
    "    dt, range_t = pars['dt'], pars['range_t']\n",
    "    Lt = range_t.size\n",
    "    tref = pars['tref']\n",
    "    \n",
    "    v = np.zeros(Lt)\n",
    "    v[0] = V_init\n",
    "    \n",
    "    if Iinj is None:\n",
    "        Iinj = np.random.normal(loc=200, scale=noise_std, size=Lt)  # Noisy input\n",
    "    \n",
    "    rec_spikes = []\n",
    "    tr = 0.\n",
    "    for it in range(Lt - 1):\n",
    "        if tr > 0:\n",
    "            v[it] = V_reset\n",
    "            tr -= 1\n",
    "        elif v[it] >= V_th:\n",
    "            rec_spikes.append(it)\n",
    "            v[it] = V_reset\n",
    "            tr = tref / dt\n",
    "        dv = (-(v[it] - E_L) + Iinj[it] / g_L) * (dt / tau_m)\n",
    "        v[it + 1] = v[it] + dv\n",
    "        v[it + 1] = np.clip(v[it + 1], -100, 100)  # Prevent overflow\n",
    "    \n",
    "    rec_spikes = np.array(rec_spikes) * dt\n",
    "    spike_train = np.zeros(Lt)\n",
    "    spike_indices = (rec_spikes / dt).astype(int)\n",
    "    spike_train[spike_indices] = 1\n",
    "    return v, spike_train\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T19:05:07.338531Z",
     "start_time": "2025-08-10T19:05:07.333281Z"
    }
   },
   "id": "c6385373e6c7ad95",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) LIF simulator\n",
    "\n",
    "Implements the leaky integrate-and-fire (LIF) dynamics and returns:\n",
    "- `v`: membrane potential trace\n",
    "- `spike_train`: binary spike indicator per time step\n",
    "\n",
    "Includes basic parameter validation.\n"
   ],
   "id": "617c851185927b56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "def truncated_normal(mean, std, low, high):\n",
    "    a, b = (low - mean) / std, (high - mean) / std\n",
    "    return truncnorm.rvs(a, b, loc=mean, scale=std)\n",
    "\n",
    "def prior():\n",
    "    # Sample voltages (mV) with loose dependencies\n",
    "    V_th = truncated_normal(mean=-55, std=2, low=-60, high=-50)\n",
    "    E_L = truncated_normal(mean=-70, std=2, low=-75, high=-60)\n",
    "    V_init = truncated_normal(mean=-70, std=2, low=-80, high=min(E_L - 0.5, -65))\n",
    "    V_reset = truncated_normal(mean=-72, std=2, low=-85, high=min(V_init - 0.5, -65))\n",
    "    \n",
    "    # Sample positive-only parameters with constraints\n",
    "    tau_m = np.clip(np.random.lognormal(mean=np.log(10), sigma=0.2), 5, 20)  # ms\n",
    "    g_L = np.clip(np.random.lognormal(mean=np.log(10), sigma=0.2), 5, 15)    # nS\n",
    "    \n",
    "    return {\n",
    "        \"V_th\": V_th,\n",
    "        \"tau_m\": tau_m,\n",
    "        \"g_L\": g_L,\n",
    "        \"V_reset\": V_reset,\n",
    "        \"V_init\": V_init,\n",
    "        \"E_L\": E_L,\n",
    "    }\n",
    "\n",
    "# Simulator\n",
    "def simulator(V_th, tau_m, g_L, V_reset, V_init, E_L):\n",
    "    pars = default_pars(\n",
    "        V_th=V_th, tau_m=tau_m, g_L=g_L,\n",
    "        V_reset=V_reset, V_init=V_init, E_L=E_L\n",
    "    )\n",
    "    v, spike_train = run_LIF(pars, Iinj=None)\n",
    "    v += np.random.normal(0, 1, v.shape)  # Add observation noise\n",
    "    return {\"voltage\": v[..., np.newaxis], \"spikes\": spike_train[..., np.newaxis]}\n",
    "\n",
    "# BayesFlow setup (simplified)\n",
    "sim = bayesflow.make_simulator([prior, simulator])\n",
    "\n",
    " # from (4000,) to (4000, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T19:05:08.599899Z",
     "start_time": "2025-08-10T19:05:08.594291Z"
    }
   },
   "id": "38122ed948461b23",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Prior + simulator wrapper\n",
    "\n",
    "- Defines a *truncated normal / lognormal* prior for LIF parameters.\n",
    "- Wraps the simulator to return the BayesFlow expected dictionary format:\n",
    "  - `voltage`: shape `(T, 1)`\n",
    "  - `spikes`: shape `(T, 1)`\n",
    "- Creates a BayesFlow simulator via `bayesflow.make_simulator`.\n"
   ],
   "id": "4d971c88819442fc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sim_draws = sim.sample(500)\n",
    "print(sim_draws[\"V_th\"].shape)\n",
    "print(sim_draws[\"voltage\"].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T19:05:11.348098Z",
     "start_time": "2025-08-10T19:05:09.673483Z"
    }
   },
   "id": "bef3a4d4a278dcc8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Quick sanity check: simulator output shapes\n",
    "\n",
    "Draws a small batch from the simulator to confirm shapes and basic functionality.\n"
   ],
   "id": "af8a666c54749e99"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "samples = [prior() for _ in range(10000)]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist([s[\"V_th\"] for s in samples], bins=30, label=\"V_th\")\n",
    "plt.hist([s[\"E_L\"] for s in samples], bins=30, label=\"E_L\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T19:05:18.008776Z",
     "start_time": "2025-08-10T19:05:13.010468Z"
    }
   },
   "id": "2e1068912845c17b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Quick sanity check: prior marginals\n",
    "\n",
    "Samples from the prior and visualizes marginals for a couple parameters (helps catch obvious prior mistakes).\n"
   ],
   "id": "ecf528bd114231ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "adapter = (\n",
    "    bayesflow.Adapter()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .concatenate([\"V_th\", \"tau_m\", \"g_L\", \"V_reset\", \"V_init\", \"E_L\"], into=\"inference_variables\")\n",
    "    .concatenate([\"voltage\", \"spikes\"], into=\"summary_variables\")\n",
    ")\n",
    "summary_network = bayesflow.networks.TimeSeriesNetwork(hidden_dim=64, summary_dim=32)\n",
    "inference_network = bayesflow.networks.CouplingFlow(num_params=6)\n",
    "workflow = bayesflow.BasicWorkflow(\n",
    "    simulator=sim,\n",
    "    adapter=adapter,\n",
    "    inference_network=inference_network,\n",
    "    summary_network=summary_network,\n",
    "    standardize=[\"inference_variables\", \"summary_variables\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T19:05:27.075768Z",
     "start_time": "2025-08-10T19:05:18.008776Z"
    }
   },
   "id": "19024e2526d299b7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) BayesFlow workflow setup\n",
    "\n",
    "Defines the data adapter, summary network, and inference network, then combines them into a `BasicWorkflow`.\n",
    "\n",
    "- Adapter concatenates parameters into `inference_variables`\n",
    "- Adapter concatenates time series into `summary_variables`\n"
   ],
   "id": "e6a8e114f9e952a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_data = workflow.simulate(20000)\n",
    "validation_data = workflow.simulate(1000)\n",
    "history = workflow.fit_offline(\n",
    "    data=training_data,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=validation_data\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:19:56.039328Z",
     "start_time": "2025-08-10T19:05:56.914840Z"
    }
   },
   "id": "2d540ced21f9c296",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Offline simulation + training\n",
    "\n",
    "Generates training/validation simulations and fits the amortized inference network offline.\n"
   ],
   "id": "2e45ef92ca0173fb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set global font sizes for all plots\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font (ticks, legends, 'r' text)\n",
    "    'axes.labelsize': 18,     # X/Y labels\n",
    "    'axes.titlesize': 20,     # Titles\n",
    "    'xtick.labelsize': 16,    # X ticks\n",
    "    'ytick.labelsize': 16,    # Y ticks\n",
    "    'legend.fontsize': 16,    # Legends\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:21:12.000733Z",
     "start_time": "2025-08-10T20:21:11.996762Z"
    }
   },
   "id": "a058581dd0d413bd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Plot styling for diagnostics\n",
    "\n",
    "Sets global font sizes for consistent and presentation-ready diagnostic plots.\n"
   ],
   "id": "61a495f66575fd88"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Generate the loss plot\n",
    "plot_loss = bayesflow.diagnostics.plots.loss(history)\n",
    "\n",
    "# Fine-tune all elements in the plot\n",
    "for ax in plot_loss.axes:\n",
    "    # Title\n",
    "    ax.title.set_size(20)\n",
    "    \n",
    "    # X and Y labels\n",
    "    ax.xaxis.label.set_size(20)\n",
    "    ax.yaxis.label.set_size(20)\n",
    "    \n",
    "    # Ticks\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    \n",
    "    # Legend (if present; loss plot may have multiple lines)\n",
    "    if ax.get_legend():\n",
    "        plt.setp(ax.get_legend().get_texts(), fontsize=16)\n",
    "        plt.setp(ax.get_legend().get_title(), fontsize=20)\n",
    "    \n",
    "    # Any annotations or text (e.g., if there are 'r' or other info; adapt if needed)\n",
    "    for text in ax.texts:\n",
    "        text.set_fontsize(16)\n",
    "\n",
    "# Show the updated plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:21:13.720157Z",
     "start_time": "2025-08-10T20:21:13.528413Z"
    }
   },
   "id": "3e70d9da954daa77",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Training diagnostics: loss trajectory\n",
    "\n",
    "Plots training vs. validation loss across epochs.\n",
    "- Useful to spot under/overfitting\n",
    "- Confirms stable optimization\n"
   ],
   "id": "a47a2b9c7fa3b295"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set the number of posterior draws you want to get\n",
    "num_datasets = 1000\n",
    "num_samples = 100\n",
    "\n",
    "# Simulate 300 scenarios\n",
    "test_sims = workflow.simulate(num_datasets)\n",
    "\n",
    "# Obtain num_samples posterior samples per scenario\n",
    "samples = workflow.sample(conditions=test_sims, num_samples=num_samples)\n",
    "j = bayesflow.diagnostics.plots.recovery(samples, test_sims)\n",
    "for ax in j.axes:\n",
    "    ax.title.set_size(36)\n",
    "    ax.xaxis.label.set_size(28)\n",
    "    ax.yaxis.label.set_size(28)\n",
    "    ax.tick_params(axis='both', labelsize=18)\n",
    "    if ax.get_legend():\n",
    "        plt.setp(ax.get_legend().get_texts(), fontsize=18)\n",
    "    for text in ax.texts:  # Targets 'r' annotations\n",
    "        text.set_fontsize(32)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:21:28.286366Z",
     "start_time": "2025-08-10T20:21:21.425508Z"
    }
   },
   "id": "f70d4697ce7959af",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Parameter recovery (simulation-based check)\n",
    "\n",
    "Simulates many datasets, draws posterior samples, and plots **recovery** (ground truth vs posterior estimates).\n"
   ],
   "id": "b15dbed0532f2066"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set the number of posterior draws you want to get\n",
    "num_datasets = 1000\n",
    "num_samples = 100\n",
    "\n",
    "# Simulate 300 scenarios\n",
    "test_sims = workflow.simulate(num_datasets)\n",
    "\n",
    "# Obtain num_samples posterior samples per scenario\n",
    "samples = workflow.sample(conditions=test_sims, num_samples=num_samples)\n",
    "g = bayesflow.diagnostics.plots.calibration_histogram(samples, test_sims)\n",
    "for ax in g.axes:\n",
    "    ax.title.set_size(36)\n",
    "    ax.xaxis.label.set_size(28)\n",
    "    ax.yaxis.label.set_size(28)\n",
    "    ax.tick_params(axis='both', labelsize=18)\n",
    "    if ax.get_legend():\n",
    "        plt.setp(ax.get_legend().get_texts(), fontsize=18)\n",
    "    for text in ax.texts:  # Targets 'r' annotations\n",
    "        text.set_fontsize(32)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-11T14:32:55.770839Z",
     "start_time": "2025-08-11T14:32:50.298782Z"
    }
   },
   "id": "7a55ec90f0eeed10",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Calibration / SBC rank histograms\n",
    "\n",
    "Simulation-based calibration (SBC) style diagnostic:\n",
    "- For well-calibrated posteriors, rank histograms should be ~uniform.\n"
   ],
   "id": "5c383621594a6d99"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "metrics = workflow.compute_default_diagnostics(test_data=1000)\n",
    "metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:21:57.587122Z",
     "start_time": "2025-08-10T20:21:49.042736Z"
    }
   },
   "id": "fdf4c52b362a2fc6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) Default diagnostics summary\n",
    "\n",
    "Computes BayesFlow’s default diagnostic metrics on held-out simulations.\n"
   ],
   "id": "e1d9ae79c5137d9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- Posterior Inference on New Observation ---\n",
    "# Simulate new test observation from true parameters\n",
    "true_params = prior()\n",
    "test_sim = simulator(**true_params)\n",
    "\n",
    "# Extract and reshape both voltage and spikes\n",
    "observed_voltage = test_sim[\"voltage\"].reshape(1, -1, 1)  # Shape: (1, 1000, 1)\n",
    "observed_spikes = test_sim[\"spikes\"].reshape(1, -1, 1)    # Shape: (1, 1000, 1)\n",
    "\n",
    "# Sample from the posterior with both summary variables\n",
    "posterior_samples = workflow.sample(\n",
    "    conditions={\"voltage\": observed_voltage, \"spikes\": observed_spikes},\n",
    "    num_samples=1000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:22:06.263266Z",
     "start_time": "2025-08-10T20:22:04.579537Z"
    }
   },
   "id": "9f0e6776594542e5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Posterior inference for one synthetic observation\n",
    "\n",
    "Samples a single set of “true” parameters, simulates an observation, and draws posterior samples conditioned on that observation.\n"
   ],
   "id": "5bf098d6217fc474"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- Visualization ---\n",
    "import seaborn as sns\n",
    "\n",
    "param_names = [\"V_th\", \"tau_m\", \"g_L\", \"V_reset\", \"V_init\", \"E_L\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(12, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, param in enumerate(param_names):\n",
    "    sns.kdeplot(posterior_samples[param].reshape(-1), ax=axs[i], fill=True, label='Posterior')\n",
    "    axs[i].axvline(true_params[param], color='r', linestyle='--', label='True value')\n",
    "    axs[i].set_title(f\"Posterior for {param}\", fontsize=28)\n",
    "    axs[i].set_xlabel(param, fontsize=18)  # Add explicit x-label if needed\n",
    "    axs[i].set_ylabel('Density', fontsize=18)\n",
    "    axs[i].tick_params(axis='both', labelsize=16)\n",
    "    axs[i].legend(fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:22:08.746217Z",
     "start_time": "2025-08-10T20:22:08.183107Z"
    }
   },
   "id": "e78c8c4654b8877",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) Posterior visualization\n",
    "\n",
    "Plots marginal posterior densities (KDE) for each parameter and overlays the true value.\n"
   ],
   "id": "fc0e824dfc9ba944"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- Minimal PPC (no plots) ---\n",
    "np.random.seed(45)\n",
    "K = 200  # posterior predictive draws\n",
    "param_names = [\"V_th\", \"tau_m\", \"g_L\", \"V_reset\", \"V_init\", \"E_L\"]\n",
    "\n",
    "# Flatten helpers\n",
    "obs_v = observed_voltage.reshape(-1)\n",
    "obs_spike_count = int(observed_spikes.sum())\n",
    "\n",
    "# Sample K synthetic datasets from posterior\n",
    "pp_volt = []\n",
    "pp_spike_counts = []\n",
    "post_idx = np.random.randint(0, posterior_samples[param_names[0]].size, size=K)\n",
    "for i in post_idx:\n",
    "    pars = {p: posterior_samples[p].reshape(-1)[i] for p in param_names}\n",
    "    sim = simulator(**pars)  # uses your default noise/current; good enough for PPC-lite\n",
    "    pp_volt.append(sim[\"voltage\"].reshape(-1))\n",
    "    pp_spike_counts.append(int(sim[\"spikes\"].sum()))\n",
    "pp_volt = np.vstack(pp_volt)\n",
    "pp_spike_counts = np.array(pp_spike_counts)\n",
    "\n",
    "# Compute pointwise predictive band + median\n",
    "v_lo = np.percentile(pp_volt, 5, axis=0); v_hi = np.percentile(pp_volt, 95, axis=0); v_med = np.median(pp_volt, axis=0)\n",
    "\n",
    "# 1) Voltage coverage (target ~90%)\n",
    "coverage = np.mean((obs_v >= v_lo) & (obs_v <= v_hi))\n",
    "\n",
    "# 2) Spike count percentile (should be non-extreme, e.g., 0.1–0.9)\n",
    "spike_percentile = np.mean(pp_spike_counts <= obs_spike_count)\n",
    "\n",
    "# 3) Subthreshold deviation (mV) using posterior-median V_th\n",
    "Vth_med = np.median(posterior_samples[\"V_th\"])\n",
    "mask_sub = obs_v < Vth_med\n",
    "subthreshold_deviation = np.mean(np.abs(obs_v[mask_sub] - v_med[mask_sub]))\n",
    "\n",
    "print(f\"PPC — voltage coverage in 90% band: {coverage*100:.1f}%\")\n",
    "print(f\"PPC — spike count percentile: {spike_percentile:.2f}\")\n",
    "print(f\"PPC — subthreshold deviation vs. predictive median: {subthreshold_deviation:.2f} mV\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:22:47.694195Z",
     "start_time": "2025-08-10T20:22:47.010019Z"
    }
   },
   "id": "37f5d409117b5cd0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Posterior predictive checks (PPC-lite)\n",
    "\n",
    "Samples parameter draws from the posterior, simulates replicated datasets, and compares:\n",
    "- Spike count distribution vs observed spike count\n",
    "- Voltage trace predictive band vs observed voltage\n",
    "\n",
    "This checks whether the inferred posterior can reproduce key features of the observed data.\n"
   ],
   "id": "d67116eddc55bb8f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# --- PPC-lite with plots ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(45)\n",
    "K = 200  # number of posterior predictive draws\n",
    "param_names = [\"V_th\", \"tau_m\", \"g_L\", \"V_reset\", \"V_init\", \"E_L\"]\n",
    "\n",
    "obs_v = observed_voltage.reshape(-1)\n",
    "obs_spike_count = int(observed_spikes.sum())\n",
    "t = default_pars()['range_t']\n",
    "\n",
    "pp_volt = []\n",
    "pp_spike_counts = []\n",
    "post_idx = np.random.randint(0, posterior_samples[param_names[0]].size, size=K)\n",
    "for i in post_idx:\n",
    "    pars = {p: posterior_samples[p].reshape(-1)[i] for p in param_names}\n",
    "    sim = simulator(**pars)  # same default noise/current\n",
    "    pp_volt.append(sim[\"voltage\"].reshape(-1))\n",
    "    pp_spike_counts.append(int(sim[\"spikes\"].sum()))\n",
    "pp_volt = np.vstack(pp_volt)\n",
    "pp_spike_counts = np.array(pp_spike_counts)\n",
    "\n",
    "# Compute PPC bands\n",
    "v_lo = np.percentile(pp_volt, 5, axis=0)\n",
    "v_hi = np.percentile(pp_volt, 95, axis=0)\n",
    "v_med = np.median(pp_volt, axis=0)\n",
    "\n",
    "# Plot: Voltage PPC ribbon\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.fill_between(t, v_lo, v_hi, alpha=0.3, label='Posterior predictive 90% band')\n",
    "plt.plot(t, v_med, 'k-', lw=1.5, label='Posterior predictive median')\n",
    "plt.plot(t, obs_v, 'r-', lw=1, alpha=0.8, label='Observed voltage')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Membrane potential (mV)')\n",
    "plt.title('PPC-lite: Voltage Trace')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Spike count PPC histogram\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(pp_spike_counts, bins=np.arange(pp_spike_counts.min()-0.5,\n",
    "                                         pp_spike_counts.max()+1.5, 1),\n",
    "         alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(obs_spike_count, color='red', linestyle='--', lw=2, label=f'Observed: {obs_spike_count}')\n",
    "plt.xlabel('Spike count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('PPC-lite: Spike Count')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-10T20:23:21.096187Z",
     "start_time": "2025-08-10T20:23:20.106738Z"
    }
   },
   "id": "a59a6fada30e0f8a",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
